Hello, if you are reading this, this is a bit of like a personal diary I am keeping to help me, (and anyone else who 
stumbles upon this repository) understand what is going on in my code. They are sectioned into days, though I do not always
remember to update this txt file each day.

DAY 1
----------------------------------
Assembly code goes from top to bottom, (duh). Most CPUs begin by booting in 16 bits, then immediately switch to 32 or 64 
bits depending on the OS, for example, Windows is a 64 bit OS, so an intel cpu in a windows machine might boot in 16 bits,
then transition immediately to 64 bits. Since this assembly code is just for booting, we specify that we are coding in 16
bits.

Next, for the BIOS to know when the OS wants to boots, it reads starting from memory address 0x7C00 and checks if there is
any code there being run. If there is, great, it'll run it and, hopefully, boot up. Another thing is the BIOS requires that
the last two lines of the boot code contain the word 0xAA55 and times 510 - ($ - $$) db 0, which tells the assembler to pad 
the remaining addresses up to 0xAA55 with null.

Now, since assembly starts at the top and goes down to a HLT instruction, it enters the start function, which tells it to
unconditionally jump to main, which it does and, (to my knowledge), saves the return address to some register. 

In the main function, we fill the register AX with 0x0000. AX is a general purpose register that is used in the x86 ISA for 
numbers-based-things. So imagine multiplcation, division, but it can also be used to just hold numbers. We put 0 into the AX 
register so we can put 0 into the DS register, because the DS register cannot manually have integers inserted into it.

Next, we have SI point to MESSAGE. MESSAGE is a static variable in the assembly code and it points to, actually, only the 
byte with ASCII value 'H'. So, in actuality, MESSAGE -> 'H'
MESSAGE + 1 -> 'E'
...
up until 0, which we define as the sentinel. So technically, this is a big data segment (a DS, one could say!)

Also, we use the DS register because the DS registers main purpose is to store the addresses of static variables and, hey, our MESSAGE variable is in fact a static variable. Eventually we want to print out the contents of the MESSAGE variable, and we do this through the instruction LODSB, which implicitly uses [DS:SI] and stores the contents of [DS:SI] into the AL register before incrementing SI to point to the next letter in the segment of code, (the letter 'E').

Of course, we're getting ahead of ourselves right now though. The next thing we do is use MOV SS, AX and MOV SP, 0x7C00.

SS and SP are similar to DS and SI in that they both use memory segmentation and both registers are basically used in pairs. They are used in pairs to point to the beginning of a segment. So, the memory segment DS:SI points to the beginning of the message "Hello World!". While SS:SP point to the beginning of the stack. Since SS is also equal to 0, and SP is equal to 0x7C00, our stack begins at 0x7C00. Sounds dangerous, right? Maybe, but the space behind 0x7C00 is safe until a limit. That is usable memory space, and since stacks are LIFO, everytime we push variables or functions into the stack, it will not actually interfere with the bootloader code. 

Next up, we CALL the puts function (since we call it, that means we save the return address into the stack, I think). Puts pushes the CURRENT INFORMATION in the SI and AX registers (pointer to the letter 'H' and 0x0000 respectively) into the stack. Then, we go into the local function of puts, print_loop, which does the LODSB which loads [DS:SI] into the AL register. We then check to see if the value in AL is the sentinel, 0, which if it is, then we are finished. Otherwise, we must now interrupt the BIOS and tell it that we want to print to video. We do this through this code in particular:

MOV AH, 0x0E
INT 0X10

The MOV AH, 0x0E tells the bios we want to interrupt, and it prepares the BIOS
INT 0x10 is an interrupt code which tells the BIOS we want to display to video the contents in the AL register, (I THINK. I know the AL register is not actually its own register, but just the lower 8 bits of the AX register, so I don't fully know how it works...).

Once we've fully displayed "HELLO WORLD!" and we hit the sentinel, the JE instruction jumps us to the done local function, which pops the AX and SI registers from the stack (thereby returning them to their original values), and then returns by also popping the saved return address from the stack.

Afterwards, the next instruction is simply a HLT, which tells the assembler that we are done.



DAY 2 TO LIKE 4, I THINK?
----------------------------------
A lot has been added now, and I feel like I need to explain some new stuff to myself so I hopefully don't forget it all later. 

1. Real Mode vs. Protected Mode.
x86 processors all start in real mode, and real mode is SUPER limiting. It is locked to 16-bit, and the total memory we have
access to is (I believe) a measly 4 Kb. This is nothing, and if we really want to get into the big boy leagues, we need more
memory soon. So, generally, people will often switch to protected mode at the end of their bootloader. Some people are 
weird, (like one of the youtubers I was following, Nanobyte), and they instead first implement a FAT16 file system, but I
did not learn that yet, and I am not very far into the dinosaur book or comet book to really know about file allocation 
table yet, so I didn't touch it.
Switching to protected mode is actually very easy, even though my code might seem to complicate it. One of the registers,
CR0, has a PE (protection enabled) bit that, on boot, is set to 0. All we have to do, to switch to protected mode, is flip 
that bit to 1, and boom! Now we're in protected mode and we're coding in 32 bits with a LOT more memory. Of course, now that 
we're in protected mode, there are also some things we've lost. In day 1, we were able to print "Hello World!" through the 
use of BIOS interrupts. The instruction "INT 0x10" allowed us to signal to the BIOS that we wanted to display to video. Now 
that we're in protected mode, we no longer have such a luxury, but in return, we do have the ability to abandon assembly 
code altogether and, eventually, switch over to C, or C++, or Python, or whatever you wanna use, (I'm gonna use C because I 
also need to learn that language). The actual switching over to C is handled by our kernel, because we can do whatever we 
want in the kernel, basically. Our bootloader is limited to 512 bytes, which, once we implement the FAT16 file system, we 
will soon realize is not a lot.

2. Global Descriptor Table
This is the 2nd thing I did, and was one of the most confusing things ever, because it surprisingly is not super well 
documented (in my opinion). In order to put it very simply, and how I understand it, the GDT works like the following:
Each segment register (DS, ES, SS, CS) have two parts to them. One is the visible part, which you can access and play around
with with the MOV instruction in x86, and it also contains the "segment selector". The other is the hidden part, which 
contains what is known as the "segment descriptor". Whenever a new segment selector is loaded onto the visible part, the CPU
automatically copies the corresponding segment descriptor from the GDT (or LDT) and puts it into the hidden part. So, what 
is contained in this hidden part? Well, the hidden, segment descriptor, contains the description for the segment, such as:
How long is the segment?
What are the access rights for the segment? (Kernel only or can the user also access them?).
Where does this memory segment start?
etc.
This method all falls under memory segmentation which, supposedly, is an obsolete method of memory storage that has now been 
replaced by paging. But I CURRENTLY do not know what paging is, as it is irrelevant to me as of right now. Eventually, I 
will find out about it. 

3. Kernel 
I haven't written the kernel as of this writing, (hopefully I will have a very simple one that just says 'Hello World from 
Kernel!' by the end of today), however, as stated previously, we eventually want to switch to the Kernel because the kernel
allows us to do a lot more and code in C. 

First things first is establishing where the Kernel should be in memory. Generally, people say to put the Kernel at 0x100000 
from the beginning of the memory, and the reason for that is because from 0x0 to 0x500 is occuped. Then, there is 512 bytes 
reserved for the bootloader in the next 638 KB, (0x500 to 0x9fc00), and finally, from 0x9fc00 to 0x100000 is occupied too.
After that, it is all free space for our taking. So, we decide to put the kernel there.

But how do we actually load the kernel? Well, to do that, we can use a form of addressing to do a huge jump from somewhere 
in the bootloader all the way to 0x100000. The easiest form of addressing to do that is CHS, (Cylinder-Head-Sector). CHS 
addressing follows the way we read the HDD, or hard drive. See, the HDD is made up of a bunch of disks stacked on top of 
each other. To better explain this, I will be using polar coordinates. Imagine the cylinder being controlled by your r, 
(radius), or how far away you are from the center. The sectors are the thetha, or like a slice of pizza from a pizza pie. 
The head is what disk we are currently on, (there are usually multiple disks stacked on each other in a modern HDD). The 
bootloader begins in 
CYLINDER: 0, HEAD: 0, SECTOR: 1. 
Most tutorials told me, and will likely tell you, to just stay in the same cylinder and head, (CYLINDER: 0 and HEAD: 0), but
just move to SECTOR 2, because that is the closest available sector where we can store the kernel binary, (or the second 
bootloader if you want one), onto.

DAY 5
----------------------------------
Day 5 was a bit uneventful. I was really tired having worked on this project all day everyday so I didn't do a whole lot and
kind of just took a break. I did do two very important things, though
1. I fixed the kernel loading up! Now it actually says "Hello World from Kernel!" from the correct memory address, (0x100000)
I will now explain a bit about how this stuff works. Volatile memory, like the main memory (or RAM) is very, very easy and 
quick and easy for the CPU to access. Hence, the CPU requires that any instructions, code, etc. is to be loaded onto the 
main memory first before it is executed. Hence also why we load the kernel onto the memory, so that one, we can execute it 
and run it, but two, so that the CPU has quick and easy access to the kernel. So, you may ask, "why even have stuff in the 
disk in the first place if its so great for the CPU?" Well, for two reasons. The first reason is because it is volative, 
meaning that
once we shut down the PC, everything in the RAM dissapears. This is a big issue, and it means that we will have to restart 
everything everytime we open the system. But wait, that might bring up a question, "how does my system store my files and 
whatnot?". It does that by saving it to the disk. The disk is non-volatile, meaning it can be saved, AND it can store a LOT 
MORE information. But it has the issue where it requires more effort and interrupts from the CPU to access, and hence, is
much less efficient. 
So, "for the CPU to process data from disk, those data must first be transferred to main memory by CPU-generated I/O calls.
In the same way, instructions must be in memory for the CPU to execute them.", (from dinosaur book, 10th edition). 
However, there is a bit of a caveat. Since the bootloader begins in real mode, (16-bit), we cannot immediately load 
the kernel into where we want, (0x100000), because of the fact that 16-bit addressing simply cannot go that high 
(even with the segmentation technique I talked about earlier, the max it can go to is 0x10000). SO, to get around this, 
I made a second stage bootloader that the first bootloader jumps to once it enters protected mode, and then in the 
second stage bootloader, since we're in 32 bits now, we are able to move the contents in 0x10000 (where the kernel 
temporarily is) to 0x100000, and then jump to 0x100000.

2. I've finally entered C! 
I still need to learn more about this process, and how link loaders exactly work, as I mostly did this step through 
tutorials.
On a later day, (probably tomorrow, as I am reserving tomorrow for catch-up-study-day, I will come back and explain 
everything
in much greater detail, and probably even fix some mistakes in my explanations). But yeah! We've finally entered C, and this
is also where, unfortunately, most tutorials end. As all that is left to do now is dive into the more "complex" stuff, and
also design the kernel to OUR fitting. It's a bit worrying, but again, I will try whatever I can. If it doesn't work, then 
I'll try to make it later. That's all for today.

DAY 6
----------------------------------
Day 6 was quite uneventful. I didn't do much. However, I did start learning about memory paging, and realized: Oh shoot, I 
should've probably maybe enabled it.

Though I don't fully understand it, I do get its basics. Memory paging is basically a form of memory allocation, in which we
create a virtual address for each program and make it believe that it has the full range from 0x0 to 0xFFFFFFFF. Of course,
it doesn't actually have the full range. That's where we come in, and we can create and use a paging table to then say "ok,
program 1 is page 0. Page 0 is supposed to be mapped to 0x200000 in the phyiscal address". Thus, we get to control the way 
memory is allocated for each program. Now, why is this better than memory segmentation? I don't know, I still need to study
that. My guess is because each page is going to be the same in its size, whilst the coding and data segments are not equal 
in memory segmentation. I don't fully know, I still need to figure that out. 
Either way, today was boring. I didn't do anything because I was feeling a bit burnt out, and instead focussed on myself 
(played games, went to the gym pet cooper)


DAY 7
----------------------------------
Day 7 I finally got around towards figuring out what I wanna do next. One of my biggest worries with this project is that
I'll hit a wall and not know what to do next. I hope that doesn't happen. Today, though, I figured "why not create a print
function?" To do this, I mostly followed nanobytes tutorial that he had, but I differed from it a little bit. Nanobyte has
paging enabled AND is still in 16 bit real mode. I have neither of those things, so I had to figure out how to make the code
myself. Though it is incomplete, and probably VERY inefficient (I am literally calling stdio.c into kernel.c, which is NOT
good), it works! I've managed to print "Hello World from C!" onto the window. The way it works is abusing the stack. In my 
kernel.s we initialized a stack. Now, before I get into anything, I should preface I am using the GCC compiler. The GCC
compiler, by default, uses a calling convention known as CDECL. The way you save stuff in CDECL is irrelevant (at least for 
now). What's important is how it deals with the stack. When you call a function with CDECL enabled, and that function has 
parameters, the CPU will then first push the arguments into the stack from right to left. For example, say I have:

foo(x, y, z). Then, with CDECL calling convention, we will first push z, then y, then x into the stack. After all the 
arguments are pushed in, then we push in the return address into the stack. Then, the ESP register (the stack pointer 
register), will point to the "top" of the stack, which just so happens to be the return address. If we want to access the
arguments sent to us in the function we just called, we can then manipulate the ESP by adding or subtracting values. Since 
each "thing" in the stack takes up 4 bytes, if we add 4 to the ESP, we get x. Add 4 again, we get y, add 4 another time, and
we get z. This is how we can access arguments sent to us in a function. When all is said is done, we can then simply RET,
which will assume that the ESP still points to the return address (which it should), and then it'll return to the address
specified on the stack. Using this knowledge, I managed to print stuff onto the video! Woohoo!

Oh, I should specify how we print stuff onto video. We do this through VGA text mode. VGA has its own segment in the memory,
and that segment lives at address 0xB8000 and continues on for a while. The way it works is that each 0xB8000 stores the 
character, and 0xB8001 stores the background color, or other stuff, of the character at 0xB8000. By the way, 0xB8000 is the 
top left corner, and adding 2 increases the column to the next character position. So, if we store the register EAX with the
character, then that means AL (bottom 8 bits of EAX) has the character, and we just have to change AH (top 8 bits of EAX) to
be the background color and stuff (and we set it to 0x0F, which means WHITE ON BLACK). This allows us to print ONE CHARACTER.
But wait, what if we want to print MORE characters? Well, to do that, we should move to C. We can define a header that has 
C's putc and puts functions. Then, we can define a C file that uses the header, and then actually implements our putc and 
puts functions. Putc is easy, since all we have to do to display a character is just, well, put in a character into our
assembly code. Puts is a bit hard, but, since we know strings are simply just an array of characters, we can just send each
character one by one into the assembly code, and voila! We are printing strings! Woohoo!
Now all that's left is to include the c files and headers into the main kernel function, use puts("Hello World!") and now
we have an actually printing function! 

Tomorrow, I will enable paging and destroy everything. I will also try to make an actual printf() function in our main
kernel.c, so we can actually start printing for real in C, instead of fake printing in C.
----------------------------------
DAY 8 & 9
I got sick on these days, so I wasn't able to work on the project much. :(
----------------------------------
DAY 10
On Day 7 I decided I wanted to turn on paging.
I decided to NOT do that just yet, as I figured out there were some issues with my puts and putc functions. First, if I 
had a long enough message, that message would not wrap around. There was no overflow management happening, so I needed to fix
that. But by far the most GLARING issue was the fact that if I had multiple puts and putc functions, puts and putc would 
magically stop working. Even MORE confusing was that if I had another function in kernel.c that I wasn't even using, 
(like it was just EXISTING in kernel.c), puts and putc would ALSO stop working. Immediately I knew this had to be an issue
between two-three culprits.
The first culprit was that I assumed something incorrectly. Perhaps I used a register that had an implicit rule, or
I was just being unoptimized and it was messing something up. For this, I decided to clean up my x86_video_whatever it was
called function, and actually use the BP register, which is what a lot of people do whenever they're messing around with the
stack.
Speaking of the stack, this brings us to the second culprit. The stack. I assumed that, maybe, I was just being stupid and
I had actually not properly set up the stack, or I just forgot how the cdecl calling convention worked??? I dunno, but
I DID end up finding that I wasn't actually using the stack at all, and that my code just so happened to work. Originally I
was using the linker script 'ld' with the flag --oformat to directly create the .bin file by linking all the C and assembly
files. This turned out to be a BAD IDEA, because for some reason, "--oformat binary" sets the size of the .bss section to 
be 0, or just drops the .bss section. This is because the .bss section is not treated the same as .data or .text, as it 
is considered "unallocated memory", and has type SHT_NOBITS, (at least I think). A section of type SHT_NOBITS may be in 
the file, but occupies no space in the file, so we have to force it to see the .bss section. The linker ld uses the 
objcopy through the BFD library. The objcopy is the real culprit, as it does not include anything of type SHT_NOBITS to
copy over. So we convert it to an ELF type first, as ELF preserves the full memory layout, THEN we use objcopy to convert
to binary, (it wont think .bss is empty this time, because the ELF file contains it already). Also, it's a good idea to
use this anyway since, according to the OSDev wiki, generally binary files are "a flat binary with no formatting at all."
which is not great. (At least, I would assume it's not great, since we would like it to format to elf-i386 32-bit)
And finally, the third culprit. I don't understand the third culprit yet, and so I will not talk about it yet.
It is late, and I still have some glaring issues with puts and putc that I need to iron out before I can make printf and whatnot. 
The biggest issue has to do with reaching the edges. The window is 80x25. So, if I have two puts functions that are 40 characters each then,
you would think, I would reach the limit. But no, instead, it breaks, and nothing is displayed instead. Oh but wait, if I just have ONE puts
function with 80 characters, then it works just fine! But if I try to add clamps, then that one puts function fails too! What is even going on??
I'm going to try fixing this tomorrow, hopefully.

----------------------------------
DAY 11
Alright so it turns out none of the culrpits I talked about previously were the issue,  (well, I mean the .bss --oformat binary stuff was 
certainly an issue that I'm glad I fixed). Instead, the issue was that in my kernel file, I was specifying it with:
SECTION _text
instead of
SECTION .text
And my link loader doesn't know what _text is, as it only knows about .text, leading to the huge issues. That one character fix seemingly fixed 
everything, (or at least I am hoping it fixed everything. I can't seem to find any bugs at the moment..).
OK. New bug was discovered while I was implementing printf. The more I implemented printf, the more and more my strings were truncating. I knew 
that the issue HAD to be memory allocation, but I couldn't for the life of me figure out what the issue was. Eventually, while looking through
the boot code, and genuinely feeling like giving up and restarting this project from scratch and actually following nanobytes tutorial 100%, 
I found out in my boot2.s I was only copying the first 512 bytes of code over to 0x100000. That is nothing, so I changed it to 4096 and 
Everything started working again. 

Furthermore, today I implemented the functionality for printf. The OSDev wiki had a page on it, so I assumed I needed to do it. Also it is
quite nice to be able to actually print things stored in variables, so why not, right? Anyway. The implementation is only really half complete.
I followed Nanobyte's tutorial, but he doesn't make use of the va_list, (even though OSDev wiki tells me to), and he's in 16-bit real mode still
so I have to change some stuff. Unfortunately, though, the stuff I changed ended up not being great ideas and now the code doesn't function. 
For one, the "continue" I have doesn't increment fmt, so in some cases, (in literally evey case), I end up being stuck in an infinite loop in
printf. Also, the number to ASCII thing definitely does not work (my emulator keeps flickering). But oh well, this is all stuff I will do for
tomorrow.
Oh yes, as for how the implementation works. On paper, it is simple. We observe printf through a sort of finite state machine. Since strings are
just arrays, we will increment through the string starting from the far left and moving rightward towards the sentinel at the end. We begin at
state NORMAL. If we discover there exists no "%", and we are in no other state, then we simply print whatever character we are currently at
and move on. If we discover a '%', then we move to a state "LENGTH". Here, we once again increment and check the next character after the '%'.
If this next character is 'h', or 'l', that means we are thinking about short or long respectively. So we increment once again to see the thing
AFTER 'h' or 'l'. If there is another 'h' or 'l', that means we're in SHORT SHORT or LONG LONG. You can't be SHORT SHORT SHORT or LONG LONG LONG
so that means the next thing that comes must mean we are printing something out, so we move to the PRINT_STATE state, where we have a bunch of
cases for various commands, like %d, %i, %x, %o, etc. 
%d implies that we have to be printing numbers. Now, we cannot just prints numbers by themselves, as they are not characters, they are ints, and
ints are usually 32 bits (4 bytes), and chars are 8 bits (1 byte). So, we have to somehow make 32 bits into 8 bits and keep the same display 
value. How would we do that? Through the power of ASCII tables. ASCII tables allow us to take integers and print them as characters. So, we must
do that through a special function. That special function is printf_number, which takes a value and prints it into an ASCII value based on a 
specific base, (base 10, 16, or 8 depending on % code). It uses long division to repeatedly divide the numbers by the base to extract digits,
and then stores the corresponding digits in reverse order. Then we can just print it in reverse order and get the ASCII value for the number. 
If you want a better-ish explanation, I would recommend watching Nanobyte's printf implementation video.
Now back to printf. After it has processed this one character, it finishes, resets the state and length back to NORMAL, and then moves onto the
next letter.
Oh, by the way, our printf is technically wrong. The header is supposed to return an int according to the C++ documentation, but I don't care. 
This is my printf. So I made it return nothing, but the parameters are the same! (const char* fmt, ...). 
Anyway, tomorrow I'll fix printf and I'll do some more studying and whatnot. Then hopefully this week I can turn on memory paging to protect
my memory.

----------------------------------
DAY 12
Today was a bit of a nothing burger day in terms of new stuff. It was really just more debugging and studying. As of right now, I believe I have
EVERYTHING in my program working smoothly. Printf actually prints everything I want it to print, (including long long hexadecimals, which is
something I almost never see, but why not). I've also updated my x86_div64_32 algorithm, after realizing that my original algorithm was trying to
divide a 64 bit number by the base (base 10, 16, or 8), and then store it. This is stupid, and obviously won't work. So I went back to Nanobyte's
video, and I discovered a new "tutorial" channel, Queso Fuego, whom also talked about the "long division method" where they take the first 32
bits, divide them by the base, store the quotient and remainder, then take the last 32 bits, append the remainder, and divide it by the base, 
before storing everything once more. Adding the two will give you the actual division, just like if you were to try and divide the 64 bits in 
one go. This worked much better, (duh), and actually allowed me to use %llx, as before I was unable to use them with my implementation. 

As for studying, I just read more of the intel manual, OSDev wiki, and the dinosaur book (specifically chapter 2), to get a better understanding
of where I want to go next. I think the next plan of action is the following
1. More studying. I really need to read more of the dinosaur book, it is a very good book and teaches the concepts quite well. I want to have read
a large chunk of it by the time I'm done with v1.0 of this project.
2. Set up memory paging. I've been talking about doing this for a while, but I think I've held it off for long enough and I need to do it soon.
3. Set up TSS w/ ESP0 stack. I don't fully know what these are yet, but the OSDev wiki recommends them
3. Set up IDT. The IDT is not only necessary for entering user mode (ring 3), but also will be quite helpful in the future for debugging purposes.
4. Enter user mode. I'm quite excited for this, as there is a lot to do after I enter user mode still. 
5. This part I need to study some more, but I believe I need to:
  - implement various user programs (a simple clock, maybe)
  - implement system calls for said user programs (a system call interface)
  - set up a timer 
  - set up scheduling (so I can multitask and not force the user to have one thing at a time. Timer is also necessary for this, paging too)
After that, I should probably implement a file system, drivers, and other shenanigans that I need to study up on. (FAT32?)

----------------------------------
DAY 12
Today was very confusing, and that is why I will be dedicating tomorrow towards a study day. Perhaps even the rest of the week, I will dedicate
to being a study-remainder-week. I need to catch up more on the x86 ASM language, as I believe I am starting to reach the point where I'm not
fulling understanding the assembly code the tutorials are giving me.
The things I did understand, though, is the newly updated putc and whatnot with proper cursor handling. Beforehand I was relying on the assembly
code and then sending in a global variable, cursor_pos. This worked, but it didn't literally update the cursor position. Now, I use a volatile
8-bit memory pointer that uses 0xB8000 as a pointer itself (bleh, jumbo of words). As I've explained before, the VGA memory address works like
the following: 0xB8000 stores a character, and 0xB8001 stores the attributes of said character, (like background color, font-color, etc.). So,
by having a buffer integer pointer that points to an 8-bit integer, we are basically saying that the variable uint8_t* g_ScreenBuffer points to
the address 0xB8000, which we are able to then print directly to, and then we can move onto the next character by playing around with the pointer.

I also started working on setting up the IDT. The IDT is, of course, for interrupts. I believe I've mentioned in this dev-log that, once we enter
protected mode, we lose the ability to use interrupts (like INT 0x10, INT 0x13, both of which we used quite extensively. 0x10 is for video memory,
0x13 combined with AH 0x02 is for reading from a disk. Fun fact: INT 0x13 AH 0x03 is for WRITING to a disk, so that's fun). I never actually
explained WHY we lose the ability to use interrupts. That's because in real mode, to be able to use interrupts, we had the IVT (interrupt vector
table) already available to us, and so we could use its many functions. But, in protected mode, the CPU now requires the implementation of the
IDT, (interrupt descriptor table) for us to not only be able to use some interrupts (like being able to get keyboard input. This will be VERY 
important once we get into user mode), but also for the hardware to give us some interrupts (divide by 0 and whatnot). Now I still don't FULLY
understand the implementation of the IDT, so I will get back on this devlog tomorrow when I have more understanding, but to my knowledge, the
IDT is very similar to the GDT, in that when an interrupt is issued to the CPU, it will look to the GDT to figure out what ISR to call, (ISRs are
interrupt service routines, they will handle interrupts, so we would have an ISR for divide by 0, for example, that would process, and then return
function back to the CPU to continue reading memory). When an interrupt is handled, the CPU, of course, needs to stop what it is doing. But it
can't just DROP what it is doing, that would be very inconvenient, imagine having to download something, and you accidentally press a key, making
the download process just stop. So, the CPU needs a way to save the information of what it does, I believe it does this through the IDT too,
in particular, if an interrupt occurs on kernel mode, (which is good), then all it has to do is push the error code, if there is one, onto the
stack, the CS register, the ES register, and the EFLAGS, (if the interrupt is from user mode, it has to switch to kernel mode and also push a
lot more stuff onto the stack). The Intel manual is more specific, so I'd recommend checking it out (go to figure 6.7, it explains it quite well).
The IDT also has some other stuff, like the interrupt gate and trap gate. I, again, don't fully understand the IDT just yet, but to my 
understanding, and according to the OSDev wiki, the trap gate sucks and is useless, so don't implement it. Just stick to the 32-bit interrupt
gate. We use the interrupt gate because it clears the IE bit (interrupt enabled) in the EFLAGS register, so if one interrupt is being processed,
more interrupts cannot come and mess up the process. The trap gate doesn't do that. Furthermore, the severity of an exception/interrupt is 
organized from most severe (0) to least severe (256). There's a big ol' table on the Intel manual that gives us the list of interrupts, 
(table 6.1 in the manual). 
Furthermore, I started to implement the PIC. My thought process, as of right now, is to follow what the OSDev wiki has told me, which is, to
be able to implement and code in interrupts into your OS in 32-bit protected mode, we need to do the following: 
- Make space for the interrupt descriptor table
- Tell the CPU where that space is (see GDT Tutorial: lidt works the very same way as lgdt)
- Tell the PIC that you no longer want to use the BIOS defaults (see Programming the PIC chips)
- Write a couple of ISR handlers (see Interrupt Service Routines) for both IRQs and exceptions
- Put the addresses of the ISR handlers in the appropriate descriptors (in Interrupt Descriptor Table)
- Enable all supported interrupts in the IRQ mask (of the PIC)
Currently, I believe I've done steps 1, 2, and 3. BUT, before moving onto implementing ISR handlers, I have come across a bug that I believe has
to do with memory (I don't have any memory management techniques as of right now, so it makes sense for these issues to arise). I believe the 
issues are arising because I'm stupid and I don't understand the things I've implemented, so I will take a step back and try to understand
EVERYTHING I've implemented, and play around with it to see how they work. And genuinely this time. Yesterday was supposed to be a study day, 
but I ended up debugging instead. I will try not to debug tomorrow, instead, I'll play around with stuff and try to understand it. Also I've been
using a lot of tutorial code. This is not good. I will also try to change and make stuff mine.
